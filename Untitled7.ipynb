{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WbzUmDoMOGRf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "awoGwf0tOIQY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 10\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "sequence_length = 3\n",
        "num_epochs = 200\n",
        "batch_size = 4\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "q77os4qnOKPb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phrases = [\n",
        "    \"the cat is fluffy\",\n",
        "    \"dog runs very fast\",\n",
        "    \"bird flies so high\",\n",
        "    \"fish swims in water\",\n",
        "    \"ant works all day\"\n",
        "]"
      ],
      "metadata": {
        "id": "Og9w61iSOMDC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = sorted(list(set(word for phrase in phrases for word in phrase.split())))\n",
        "word_to_idx = {word: idx for idx, word in enumerate(words)}\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
        "vocab_size = len(word_to_idx)\n",
        "num_classes = vocab_size"
      ],
      "metadata": {
        "id": "WDLuBi2dON8j"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Vocabulary ({vocab_size} words): {word_to_idx}\")\n",
        "print(f\"Expected target words: {[phrase.split()[3] for phrase in phrases]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdESKD41OQMN",
        "outputId": "3d327d06-61cc-4a42-c235-d94caa48d72b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary (20 words): {'all': 0, 'ant': 1, 'bird': 2, 'cat': 3, 'day': 4, 'dog': 5, 'fast': 6, 'fish': 7, 'flies': 8, 'fluffy': 9, 'high': 10, 'in': 11, 'is': 12, 'runs': 13, 'so': 14, 'swims': 15, 'the': 16, 'very': 17, 'water': 18, 'works': 19}\n",
            "Expected target words: ['fluffy', 'fast', 'high', 'water', 'day']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for phrase in phrases:\n",
        "    words = phrase.split()\n",
        "    target_idx = word_to_idx[words[3]]\n",
        "    assert target_idx < num_classes, f\"Target index {target_idx} for word '{words[3]}' is out of bounds for num_classes={num_classes}\"\n",
        "    print(f\"Phrase: '{phrase}', Target word: '{words[3]}', Target index: {target_idx}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkjKbvVOOSP2",
        "outputId": "1b947c9c-6ccc-4cfd-f96d-4ee8b445ff78"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phrase: 'the cat is fluffy', Target word: 'fluffy', Target index: 9\n",
            "Phrase: 'dog runs very fast', Target word: 'fast', Target index: 6\n",
            "Phrase: 'bird flies so high', Target word: 'high', Target index: 10\n",
            "Phrase: 'fish swims in water', Target word: 'water', Target index: 18\n",
            "Phrase: 'ant works all day', Target word: 'day', Target index: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for phrase in phrases:\n",
        "    words = phrase.split()\n",
        "    input_indices = [word_to_idx[word] for word in words[:3]]\n",
        "    target_index = word_to_idx[words[3]]\n",
        "    data.append((input_indices, target_index))"
      ],
      "metadata": {
        "id": "UgklFnlOOUGD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs, target = self.data[idx]\n",
        "        return torch.tensor(inputs, dtype=torch.long), torch.tensor(target, dtype=torch.long)"
      ],
      "metadata": {
        "id": "7hiZn6I8OV3K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset(data)\n",
        "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True)"
      ],
      "metadata": {
        "id": "9CMq5JHyOX2P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(vocab_size, input_size)\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        x = self.embedding(x)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "rIAjZcGBOZhR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
      ],
      "metadata": {
        "id": "qjyAEZaKOcSL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Bq9wjkESOeQX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_total_steps = len(data_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, targets) in enumerate(data_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycEKTCZxOfwp",
        "outputId": "083a28d2-3af0-4008-8bc9-a5ae9be1d68e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/200], Step [1/2], Loss: 0.0696\n",
            "Epoch [20/200], Step [2/2], Loss: 0.0567\n",
            "Epoch [40/200], Step [1/2], Loss: 0.0133\n",
            "Epoch [40/200], Step [2/2], Loss: 0.0112\n",
            "Epoch [60/200], Step [1/2], Loss: 0.0078\n",
            "Epoch [60/200], Step [2/2], Loss: 0.0090\n",
            "Epoch [80/200], Step [1/2], Loss: 0.0055\n",
            "Epoch [80/200], Step [2/2], Loss: 0.0065\n",
            "Epoch [100/200], Step [1/2], Loss: 0.0044\n",
            "Epoch [100/200], Step [2/2], Loss: 0.0037\n",
            "Epoch [120/200], Step [1/2], Loss: 0.0032\n",
            "Epoch [120/200], Step [2/2], Loss: 0.0036\n",
            "Epoch [140/200], Step [1/2], Loss: 0.0026\n",
            "Epoch [140/200], Step [2/2], Loss: 0.0029\n",
            "Epoch [160/200], Step [1/2], Loss: 0.0022\n",
            "Epoch [160/200], Step [2/2], Loss: 0.0023\n",
            "Epoch [180/200], Step [1/2], Loss: 0.0019\n",
            "Epoch [180/200], Step [2/2], Loss: 0.0019\n",
            "Epoch [200/200], Step [1/2], Loss: 0.0016\n",
            "Epoch [200/200], Step [2/2], Loss: 0.0015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in data_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy on the dataset: {accuracy}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9_JPUyROhpV",
        "outputId": "40050bdb-5368-4995-e9de-34685ccf653b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the dataset: 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_phrase = \"the cat is\"\n",
        "test_words = test_phrase.split()\n",
        "try:\n",
        "    test_indices = [word_to_idx[word] for word in test_words]\n",
        "    print(f\"Test phrase: '{test_phrase}', Input indices: {test_indices}\")\n",
        "    test_tensor = torch.tensor([test_indices], dtype=torch.long).to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(test_tensor)\n",
        "        _, predicted_idx = torch.max(output, 1)\n",
        "        predicted_word = idx_to_word[predicted_idx.item()]\n",
        "        print(f\"Output logits shape: {output.shape}, Predicted index: {predicted_idx.item()}, Predicted word: {predicted_word}\")\n",
        "except KeyError as e:\n",
        "    print(f\"Error: Word '{e}' in test phrase not found in vocabulary.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohJbzn2COkUB",
        "outputId": "701eb6d9-d909-4cf4-c1d0-a82884ee1303"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test phrase: 'the cat is', Input indices: [16, 3, 12]\n",
            "Output logits shape: torch.Size([1, 20]), Predicted index: 9, Predicted word: fluffy\n"
          ]
        }
      ]
    }
  ]
}